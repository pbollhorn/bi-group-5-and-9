{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f64ef66",
   "metadata": {},
   "source": [
    "# read_tmdb_data.ipynb\n",
    "\n",
    "This notebook reads JSON data from TMDB's API and stores it as CSV files:\n",
    "- **movies.csv**: Data on XXXX movies from United States from 2000-2023\n",
    "- **credits.csv**: Data on credits for all persons in these movies (both cast and crew).\n",
    "- **persons.csv**: Data on all actors that appear in these movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "tmdb_api_token = os.getenv(\"TMDB_API_TOKEN\")\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {tmdb_api_token}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8901a6f2",
   "metadata": {},
   "source": [
    "First we request movie_ids for all movies that live up to these requirements:\n",
    "- From the United States\n",
    "- From the years 2000-2023\n",
    "- With original_langauge = english\n",
    "- With TMDB vote count â‰¥ 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c8d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = (\n",
    "    \"https://api.themoviedb.org/3/discover/movie\"\n",
    "    \"?include_adult=false\"\n",
    "    \"&include_video=false\"\n",
    "    \"&language=en-US\"\n",
    "    \"&with_original_language=en\"\n",
    "    \"&with_origin_country=US\"\n",
    "    \"&vote_count.gte=30000\"\n",
    "    \"&primary_release_date.gte=2000-01-01\"\n",
    "    \"&primary_release_date.lte=2023-12-31\"\n",
    "    \"&sort_by=primary_release_date.asc\"\n",
    ")\n",
    "\n",
    "movie_ids = []\n",
    "\n",
    "# Loop through all pages (adjust max page if needed)\n",
    "for page in range(1, 501):\n",
    "    url = f\"{base_url}&page={page}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Status code: {response.status_code} Text: {response.text}\")\n",
    "    \n",
    "    # Extract movie_results from the response\n",
    "    movie_results = response.json().get(\"results\") \n",
    "    \n",
    "    # Stop if we have reached the last page\n",
    "    if not movie_results:\n",
    "        break\n",
    "\n",
    "    # Extract movie_ids from the movie_results\n",
    "    movie_ids.extend([movie[\"id\"] for movie in movie_results])\n",
    "    \n",
    "    sleep(0.02)  # Just to be sure we don't request too many requests\n",
    "\n",
    "print(f\"Number of movie ids found: {len(movie_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98063c0d",
   "metadata": {},
   "source": [
    "Then we request movie data for all these movie_ids, and store that in a dataframe and a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b351cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies = []\n",
    "\n",
    "# Loop through all movie_ids and request movie data\n",
    "for movie_id in movie_ids:\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{movie_id}?language=en-US&append_to_response=credits\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Status code: {response.status_code} Text: {response.text}\")\n",
    "    \n",
    "    # Extract the movie data from the response\n",
    "    movie = response.json()\n",
    "\n",
    "    # Simplify dictionaries to list of ids\n",
    "    movie[\"genre_ids\"] = [genre[\"id\"] for genre in movie[\"genres\"]]\n",
    "    movie[\"spoken_languages\"] = [language[\"iso_639_1\"] for language in movie[\"spoken_languages\"]]\n",
    "    movie[\"production_company_ids\"] = [company[\"id\"] for company in movie[\"production_companies\"]]\n",
    "    movie[\"production_countries\"] = [country[\"iso_3166_1\"] for country in movie[\"production_countries\"]]\n",
    "    movie[\"collection_id\"] = movie[\"belongs_to_collection\"][\"id\"] if movie[\"belongs_to_collection\"] else pd.NA\n",
    "    movie[\"cast_person_ids\"] = [cast_member[\"id\"] for cast_member in movie[\"credits\"][\"cast\"]]\n",
    "    movie[\"cast_credit_ids\"] = [cast_member[\"credit_id\"] for cast_member in movie[\"credits\"][\"cast\"]]\n",
    "    movie[\"crew_person_ids\"] = [crew_member[\"id\"] for crew_member in movie[\"credits\"][\"crew\"]]\n",
    "    movie[\"crew_credit_ids\"] = [crew_member[\"credit_id\"] for crew_member in movie[\"credits\"][\"crew\"]]\n",
    "    del movie['genres']\n",
    "    del movie['production_companies']\n",
    "    del movie[\"belongs_to_collection\"]   \n",
    "    del movie[\"credits\"]\n",
    "    \n",
    "    all_movies.append(movie)\n",
    "    sleep(0.02)  # Just to be sure we don't request too many requests\n",
    "\n",
    "df_movies = pd.DataFrame(all_movies)\n",
    "print(f\"Total movies collected: {len(df_movies)}\")\n",
    "\n",
    "df_movies.to_csv(\"../movie_data/movies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a7250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a74ebe",
   "metadata": {},
   "source": [
    "Then we run through the movie dataframe and find all unique actor_ids.\n",
    "\n",
    "And then we request data for all these actor_ids, and store that in a dataframe and a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9456a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten and combine the two columns\n",
    "# all_person_ids = df_movies['cast_person_ids'].explode().tolist() + df_movies['crew_person_ids'].explode().tolist()\n",
    "\n",
    "all_person_ids = df_movies['cast_person_ids'].explode().tolist()\n",
    "\n",
    "# Get unique person IDs\n",
    "unique_person_ids = set(all_person_ids)\n",
    "len(unique_person_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc138ebe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     person \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     12\u001b[0m     all_persons\u001b[38;5;241m.\u001b[39mappend(person)\n\u001b[1;32m---> 13\u001b[0m     sleep(\u001b[38;5;241m0.02\u001b[39m)  \u001b[38;5;66;03m# Just to be sure we don't request too many requests\u001b[39;00m\n\u001b[0;32m     16\u001b[0m df_persons \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_persons)\n\u001b[0;32m     17\u001b[0m df_persons\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_persons = []\n",
    "\n",
    "for person_id in unique_person_ids:\n",
    "    url = f\"https://api.themoviedb.org/3/person/{person_id}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Status code: {response.status_code} Text: {response.text}\")\n",
    "    \n",
    "    # Extract the person data from the response\n",
    "    person = response.json()\n",
    "    \n",
    "    all_persons.append(person)\n",
    "    sleep(0.02)  # Just to be sure we don't request too many requests\n",
    "    \n",
    "    \n",
    "df_persons = pd.DataFrame(all_persons)\n",
    "df_persons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_persons.rename(columns={'id': 'actor_id'}, inplace=True)\n",
    "# danish_actors = pd.merge(danish_actors, df_persons, on='actor_id')\n",
    "# danish_actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# danish_actors.to_csv(\"../movie_data/danish_actors.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
